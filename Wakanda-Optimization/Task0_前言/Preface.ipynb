{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 写在课程前面的话\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在食用课程之前$,$ 笔者想简单介绍一下这门课到底讲什么$,$ 又想传递给读者什么信息.\n",
    "\n",
    "相信有过数模参赛经验的小伙伴对优化这个词并不陌生$,$ 我们在比赛中总会遇到诸如\"确定最佳方案\"\"求出最佳的配比\"此类的\"最值\"问题$,$ 而在比赛细节中我们往往也需要\"拟合最佳的参数\"$,$ 这些都是大大小小的**优化问题**$,$ 而笔者想利用这门课抛砖引玉$,$ 当成是未接触过优化以及曾接触但不熟悉的同学的一块优化敲门砖. 本课程旨在以最简单但不平凡的例子渗透介绍优化范畴的两个核心内容: **优化建模**$,$ **下降算法**$,$ 而对于优化类的问题$,$ 如何建模与如何算法求解也是最重要的部分.\n",
    "\n",
    "我们涉及的优化模型由三个基本组成: 决策变量 $x_1,x_2,\\cdots,x_n$——影响目标的自变量$,$ 目标函数 $f(x_1,x_2,\\cdots,x_n)$——确定最佳决策的指标依据$,$ 约束条件 $c_i(x_1,x_2,\\cdots,x_n)\\leqslant(=,\\geqslant) 0$——现实中的限制. 由于本次课程讨论的大多数都是最简单的线性函数$,$ 为表述简单$,$ 我们会尽可能多的采用向量语言: 如利用向量 $\\boldsymbol{x}=(x_1,x_2,\\cdots,x_n)^T$ 表示决策变量$,$ 或利用矩阵来表达如下的约束\n",
    "\n",
    "$$A\\boldsymbol{x}\\leqslant \\boldsymbol{b}\\Leftrightarrow \n",
    "\\begin{cases}\n",
    "a_{11}x_1+a_{12}x_2+\\cdots+a_{1n}x_n\\leqslant b_1\\\\\n",
    "a_{21}x_1+a_{22}x_2+\\cdots+a_{2n}x_n\\leqslant b_2\\\\\n",
    "\\vdots\\\\\n",
    "a_{m1}x_1+a_{m2}x_2+\\cdots+a_{mn}x_n\\leqslant b_m\\\\\n",
    "\\end{cases},A=\\begin{bmatrix}\n",
    "a_{11}&a_{12}&\\cdots&a_{1n}\\\\\n",
    "a_{21}&a_{22}&\\cdots&a_{2n}\\\\\n",
    "\\vdots&\\vdots&\\ddots&\\vdots\\\\\n",
    "a_{m1}&a_{m2}&\\cdots&a_{mn}\\\\\n",
    "\\end{bmatrix}.$$\n",
    "\n",
    "此外$,$ 我们用 $R,R^n$ 代表实数域以及 $n$ 维实数 (向量) 空间$,f:R^n\\to R$ 代表 $n$ 元实值函数. \n",
    "\n",
    "用规范化的语言$,$ 我们现实中遇到的所有优化问题都可描述为如下的形式:\n",
    "\n",
    "\\begin{align}\n",
    "\\tag{0.1}\\label{eq 0.1}&\\min f(\\boldsymbol{x})\\\\\n",
    "s.t.&\\tag{0.2}\\label{eq 0.2}\\begin{cases}\n",
    "c_i(\\boldsymbol{x})\\leqslant 0,i=1,2,\\cdots,m\\\\\n",
    "c_j(\\boldsymbol{x})=0,j=1,2,\\cdots,k\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "其中$,\\boldsymbol{x}\\in R^n,f:R^n\\to R,$ 并且我们不要求目标函数 $f$ 以及约束函数 $c_i,c_j$ 有什么多余的性质如可微 (这一点对刚入门的初学者而言是比较反直觉的)$,$ 对于求极大值的问题$,$ 可以等价写为\n",
    "\n",
    "$$\\max f(\\boldsymbol{x})\\Leftrightarrow \\min -f(\\boldsymbol{x}).$$\n",
    "\n",
    "优化问题 $\\eqref{eq 0.1}$ 中$,$ 约束 $\\eqref{eq 0.2}$ 构成的子集称为**可行域** $D,$ $D$ 中的点是符合 $\\eqref{eq 0.1}$ 要求的点$,$ 称为**可行解**$,$ 令 $f(\\boldsymbol{x})$ 最小的可行解 $\\boldsymbol{x}_0$ 称为**最优解**$,$ 我们一般用\n",
    "\n",
    "$$\\mathrm{argmin} \\{f(\\boldsymbol{x})\\mid \\boldsymbol{x}\\in D\\}$$\n",
    "\n",
    "记为 $\\eqref{eq 0.1}$ 的最优解. 当 $D=R^n$ 时 $\\eqref{eq 0.1}$ 称为**无约束优化问题**$,$ 相应地 $D\\subsetneq R^n$ 时称之为**约束优化问题**. \n",
    "\n",
    "在高中的时候我们就已经学过利用导数零点求极值点的方式$,$ 然而对于一个大规模的优化问题而言 (决策变量多$,$ 即 $\\boldsymbol{x}$ 维数高)$,$ 求导 (梯度) 并非那么简单$,$ 而且目标函数 $f$ 不一定那么可导$,$ 同时局部最小值不一定是全局最小值 (凸问题的性质)$,$ 这使得我们求解难度大大攀升. 在一般的问题求解中$,$ 我们往往是采用**迭代**的**下降算法**求解局部的极小值.\n",
    "\n",
    "我们涉及的下降算法基本思想是生成一列递减的点 $\\{\\boldsymbol{x}_n\\}_{n=1}^{\\infty}$ 来逼近 $\\eqref{eq 0.1}$ 的最优解$,$ 一般由以下几步组成:\n",
    "\n",
    "1. 确定初始解 $\\boldsymbol{x}_1$.\n",
    "\n",
    "2. 确定迭代方式 $\\boldsymbol{x}_{n+1}=g(\\boldsymbol{x}_n)$ 使得 $f(\\boldsymbol{x}_{n+1})\\leqslant f(\\boldsymbol{x}_n),n=1,2,\\cdots$.\n",
    "\n",
    "3. 确定终止准则 (计算机只能迭代有限点$,$ 我们希望在有限步能尽可能接近最优解)——当 $\\boldsymbol{x}_n$ 与 $f(\\boldsymbol{x}_n)$ 满足什么条件时$,$ 认为 $\\boldsymbol{x}_n$ 最小值的近似点$,$ 终止算法.\n",
    "\n",
    "迭代方式是下降算法最核心的一步$,$ 它影响着算法生成的点列能否收敛到最优解$,$ 以及收敛的速度 (即算法运行的时间)$,$ 这在实际的计算中是重中之重.\n",
    "\n",
    "本课程介绍的是最简单的一类优化问题: 目标函数与约束条件都是线性的$,$ 称为**线性规划问题(模型)**$,$ 在日常生活中蕴含着非常多地线性规划问题$,$ 如生产策略$,$ 工作指派等等$,$ 所以建立线性规划模型事实上是在现实生活中非常常见的$,$ 而由于性质的优越$,$ 线性规划问题的下降算法设计也是非常简单的——即我们接下来要学习的单纯形法与分支定界法.\n",
    "\n",
    "笔者在这里$,$ 借用比赛真题$,$ 详细展开线性规划模型如何应用到题目的建模中$,$ 以及讨论建模后如何设计对应的算法进行求解$,$ 带同学们感受建模与设计算法过程中的思路$,$ 以此让同学们熟悉优化范畴的问题$,$ 激发同学们解决优化问题的思维. 而由于课程设置是入门性的$,$ 加之笔者笔力与时间有限$,$ 故在本次课程中没有介绍更高级的优化知识$,$ 如非线性优化问题 (连续变量类)$,$ 组合优化问题 (离散变量类) 相关的建模以及理论知识$,$ 当然$,$ 笔者希望同学们在本次课程中能体会到优化建模的魅力$,$ 更加有信心的去学习更高深的优化知识."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
