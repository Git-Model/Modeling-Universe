{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习入门——必知必会"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 导言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 宏观理解机器学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 什么是机器学习？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习也被称为统计学习，是关于计算机基于数据构建概率统计模型、并运用模型对数据进行预测与分析的一门学科。以上描述是李航老师在《统计学习方法》给出的机器学习（统计学习）的定义。在这里，我们解构一下这个定义，让大家更好地理解什么是机器学习。\n",
    "\n",
    "第一个关键词是“基于数据”。数据作为机器学习研究的对象，可以说机器学习的多样性来源于数据的多样性——我们使用何种机器学习模型，取决于待分析数据的种类与特点。例如，我们在执行二分类任务时，如果散点图显示两个种类的样本存在明显的线性可分性，那么使用一个简单的线性机器学习分类算法（如线性判别分析LDA）就可以轻松完成任务；若样本线性不可分，我们则可以考虑使用核函数支持向量机算法；如果数据是文字、图像等高维特征的数据，那么则可以使用深度学习的算法去解决。总而言之，基于数据选择合适的机器学习算法至关重要。\n",
    "\n",
    "第二个关键词是“预测与分析”。预测与分析是机器学习的两个主要的任务，更进一步地说，是对**未知新数据**的预测与分析。预测的意义不言而喻，现实中的许多应用都是各种预测问题，例如，银行根据客户的各类指标推断是否应该给其贷款、垃圾邮件分类器识别垃圾邮件以保护我们的邮箱免受侵扰等等。而分析则是指从数据中挖掘新的信息与知识，给我们带来启发，例如，在研究各因素对商品销售量的场景中，我们会更关注各因素与商品销售量间的正负相关关系，从而指导我们调整销售策略。\n",
    "\n",
    "值得注意的是，如果我们以预测作为机器学习的主要目标，那么在建模的时候应当注重模型的预测精度，而对模型的解释可以不用太在意。事实上，当前具有强大预测性能的模型大多都是黑盒模型，如各种集成学习算法以及深度学习算法，它们的模型可解释性差，我们难以解释其中一些参数的含义与统计性质。而如果我们以分析作为主要目标，那么我们应当尽可能选择可解释性强的模型。\n",
    "\n",
    "总结一下，机器学习总的目标就是**根据数据特点考虑学习（采用）怎样的模型，使得模型能对数据进行准确的预测与分析，同时在保持准确的前提下，也要考虑模型的学习效率。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 课程定位"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次机器学习课程主要服务于有建模需求的同学，力求让同学们通过本轮课程的学习，明白各种机器学习模型的简要原理、应用场景、注意事项，并基于python强大的机器学习库scikit-learn完成对各种机器学习算法的实践。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 机器学习算法的分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习是一个范围广、内容多、应用宽泛的领域，现在不存在一个统一的理论体系涵盖所有内容。不同算法模型间分类的角度有很多，现在我们用一个较为常见的分类标准：样本是否存在输出变量$y$，将算法划分为监督学习算法与无监督学习算法（事实上还存在半监督学习算法，但本次课程不讨论它们）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 监督学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 什么是监督学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "监督学习(supervised learning)是指从标注数据（带有因变量的数据）中学习预测模型的机器学习问题。本质上，监督学习的本质是学习输入自变量$X$到输出因变量$y$的映射$f$的规律。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 监督学习的两大应用——分类与回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据应变量$y$的性质，监督学习主要可以分为两大应用问题：分类与回归。若$y$取有限个离散值，则问题是分类问题；若$y$是连续变量，则问题是回归问题。\n",
    "\n",
    "在上面的举例中，商品销售额研究问题就是回归问题，因为因变量$y$销售额是一个连续变量；而垃圾短信过滤问题则是一个分类问题，因为当我们把因变量$y$定义成短信类别，将垃圾短信定义为$y=1$，正常短信定义为$y=0$，则$y$只有0和1两个离散的取值。\n",
    "\n",
    "分类与回归问题的算法类型、问题的解决范式有些许不同，接下来让我们看看它们的区别所在吧！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**· 分类问题的解决范式**\n",
    "\n",
    "分类问题以二分类问题为主，包含**模型学习（训练模型）** 与**对新样本数据进行预测分类**两个过程\n",
    "\n",
    "1. 在学习过程中，根据已知的训练集利用给定的模型算法训练出一个分类器；\n",
    "\n",
    "2. 在分类过程中，利用训练完毕的分类器对新的样本数据进行分类。\n",
    "\n",
    "分类问题的解决过程范式图如下\n",
    "\n",
    "<img src='./images/分类范式.jpg'>\n",
    "\n",
    "如图所示，分类器的形式有两种，一种是条件概率分类器$P\\left( Y|X \\right) $，一种判决函数分类器$Y=f(X)$。\n",
    "\n",
    "概率分类器$P\\left( Y|X \\right) $输出在当前样本自变量$X$下，因变量$Y$为某个特定输出$y_i$的条件概率，然后再对$Y$在不同输出值下的概率值进行比较，概率最大的类别则为分类器对新样本预测的类别。举个例子：在垃圾短信分类器中，若$P\\left( Y=1|X \\right) =0.7$，$P\\left( Y=0|X \\right) =0.3$，即对于样本特征$X$的输入，分类器将其判别为垃圾短信的概率为0.7，判别为正常短信的概率为0.3，那么我们则采纳概率较大的可能，将短信判别为垃圾短信。\n",
    "\n",
    "判决函数分类器$Y=f(X)$则是根据函数值$Y$的值对样本的类别进行判断。通常地，$f(X)=0$是很多分类器的临界点，若$f(X)<0$，则将样本判别为某个类别；若$f(X)>0$，则将样本判别为另一个类别。\n",
    "\n",
    "以条件概率作为分类器的算法通常是基于概率的算法，如决策树、朴素贝叶斯、线性判别等等；而以判决函数作为分类器的算法则往往是非概率算法，如支持向量机、k邻近、神经网络等等。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**· 回归问题的解决范式**\n",
    "\n",
    "回归时监督学习的另一个重要的问题。它的任务是预测自变量$X$与因变量$Y$之间的关系，当自变量$X$的值发生变化时，因变量$Y$将同时发生怎样的变化。事实上，回归问题的学习过程等价于用一个函数$f$对训练集数据$(x_i,y_i)$进行拟合——选择一条函数曲线使其很好地拟合已知数据、并很好地预测未知数据。\n",
    "\n",
    "回归问题的解决范式与分类问题是相似的，也包含**模型学习（训练模型）** 与**对新样本数据进行预测**两个过程，只不过模型的输出$Y$是一个连续变量而不是有限离散变量。\n",
    "\n",
    "回归问题的解决过程范式图如下\n",
    "\n",
    "<img src='./images/回归范式.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 无监督学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 什么是无监督学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "无监督学习(unsupervised learning)是指无标注数据（不带有因变量）中学习预测模型的机器学习问题。本质上，无监督学习的本质是学习数据中的统计规律或潜在结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 无监督学习的意义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "监督学习的意义很容易理解——建立自变量与因变量的映射关系，一方面精准预测新样本的因变量，另一方面可以更好地理解自变量与因变量间的关系。监督学习中的因变量$Y$就像是一盏盏明灯，指引着各种算法找到那个最优的映射关系$f$。\n",
    "\n",
    "然而，无监督学习在一定程度上就更具挑战性了。没有了因变量的存在，我们似乎很难“拟合”出一个模型用于预测。那么，无监督学习究竟是干什么的呢？答案是：理解与挖掘自变量间的关系。我们以无监督学习中常见的聚类算法为例，向大家介绍无监督学习的意义。\n",
    "\n",
    "在市场研究中，我们可以获取许多潜在消费者的特征变量，如家庭收入、消费习惯等等。我们想将消费者划分为低、中、高消费群，在不同消费群之间执行不同的营销策略。事实上，如果每个消费者的消费群归属是已知的，那么我们就可以用一个监督学习分类算法训练出一个分类器，再对新消费者样本进行分类判别。然而，消费群归属在实际情况中是不可能知道的，因为没有人会告诉你它属于哪个群体，换句话说，不会有一个“消费群归属”的变量作为因变量给我们进行监督学习。\n",
    "\n",
    "那么这该怎么办呢？我们思考一下，既然无法直接获取消费群归属的情况，那我们能不能基于已知的消费者数据$X$，寻找其中的规律然后自己构建一套规则$f$，人为地给他们划分呢？也就是说，将$X\\rightarrow f\\left( X \\right) $，然后根据每个样本$f(X)$的表现自主地给他们划分。**这就是无监督学习的基本思想——寻找一套规则$f$，使得初始自变量$X$变换为$f(X)$后，可以更好地呈现出数据中的某些特点。我们既可以直接根据无监督学习的结果进行人为的判别，也可以将其作为整个建模过程中的一种“数据处理”。**\n",
    "\n",
    "回到上述例子，我们可以用聚类分析算法解决之。聚类分析的目标是基于自变量$X$将观测样本归入不同的群，消费群相同的消费者，它们的某些自变量表现是相似且接近的，如果算法可以找出不同消费群自变量的表现模式，那将有利于我们人为地分类。我们看看以下两个图\n",
    "\n",
    "<img src='./images/聚类.jpg'>\n",
    "\n",
    "以上两个图的样本都只有两个自变量$X_1$与$X_2$，左图所示的三个群界限分明，聚类算法可以成功地识别三个群；右图相对而言界限模糊，聚类任务相对前者较难。然而，实际情况中，变量的个数肯定不止两个，此时直观地图形检查法不再是一个可行的方法，我们就需要借用自动聚类的算法了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 无监督学习的解决范式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "无监督学习的解决范式和监督学习的解决范式也大致相似，也是先根据训练数据学习出一个模型，再使用模型对数据进行预测。其实与其称之为预测，我更愿把其称为“转换”，即将原始自变量$X$转换为新的变量$f(X)$。\n",
    "\n",
    "无监督学习的解决范式示意图如下\n",
    "\n",
    "<img src='./images/无监督范式.jpg'>\n",
    "\n",
    "无监督学习的模型有三类：函数模型$f(X)$，条件概率分布模型$P\\left( Y|X \\right) $与条件概率分布模型$P\\left( X|Y \\right) $。\n",
    "\n",
    "在预测过程中，前两个模型都是将$X$转换成另一个输出值$Y$，即有：$y_{N+1}=f\\left( x_{N+1} \\right) $或$y_{N+1}=arg\\,\\,\\max \\left( P\\left( y|x_{N+1} \\right) \\right) $，聚类算法与降维算法多为这种模型。而最后一种模型则输出的是在自变量$X$恰为当前输入值时的概率估计。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 机器学习的基础概论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一章，我们将学习机器学习中一些必须要掌握的理论知识，它们是许多机器学习模型的共同内核。掌握它们，我们将在后续的对每种算法的学习中更容易串联起彼此的联系，这将有助于我们理解、学习、整理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 符号定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为方便后续各种算法的学习，我们在这里对各种数学符号进行统一的规定。\n",
    "\n",
    "**· 变量、变量取值与特征向量**\n",
    "\n",
    "自变量与因变量用大写字母表示，自变量为$X$，因变量为$Y$。\n",
    "\n",
    "变量在某个样本上的取值则用小写字母表示，自变量为$x$，因变量为$y$。\n",
    "\n",
    "变量可以是单变量的标量，也可以是多变量的向量，但由于机器学习通常都是同时处理多变量的，因此除特别声明外，教程中所有变量都是列向量。\n",
    "\n",
    "具有$n$个特征的样本实例$x$的特征向量记为\n",
    "$$\n",
    "x=\\left(x^{(1)}, x^{(2)}, \\cdots, x^{(i)}, \\cdots, x^{(n)}\\right)^{\\mathrm{T}}\n",
    "$$\n",
    "其中，$x^{(i)}$表示$x$的第$i$个特征。\n",
    "\n",
    "特别地，对于第$i$个样本，其特征向量记为\n",
    "$$\n",
    "x_i=\\left(x_i^{(1)}, x_i^{(2)}, \\cdots, x_i^{(n)}\\right)^{\\mathrm{T}}\n",
    "$$\n",
    "\n",
    "**· 样本数据集**\n",
    "\n",
    "样本数据集就是由各种样本组成的数据集，通常分为训练数据集与测试数据集，模型的训练是基于训练数据集的，预测则是基于测试数据集的。在这里我们定义训练数据集的符号（因为后续的模型学习都是基于训练集的）。\n",
    "\n",
    "对于监督学习，训练数据由特征向量$x_i$与对应的因变量$y_i$组成，表示为：\n",
    "$$\n",
    "T=\\left\\{\\left(x_1, y_1\\right),\\left(x_2, y_2\\right), \\cdots,\\left(x_N, y_N\\right)\\right\\}\n",
    "$$\n",
    "对于无监督学习，训练数据只由特征向量$x_i$构成，表示为：\n",
    "$$\n",
    "U=\\left\\{x_1, x_2, \\cdots, x_N\\right\\}\n",
    "$$\n",
    "以上两种训练集的样本个数均为$N$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 机器学习方法三要素"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所谓机器学习方法三要素，就是我们可以通过这三个要素对任何一个机器学习方法进行全面地认知（如模型形式、训练方法、计算方法）等。机器学习方法由以下三要素组成：\n",
    "$$\n",
    "\\text{方法}=\\text{模型}+\\text{策略}+\\text{算法}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所为模型，就是在机器学习中最终需要得出的条件概率分布或决策函数，然后使用这个模型对新样本进行预测、或者进行变量之间的分析。\n",
    "\n",
    "对于每一种机器学习方法而言，它们的模型是确定的。例如，在线性回归方法中，它的模型就是线性回归函数：\n",
    "$$\n",
    "y=\\beta _0+\\beta _1x^{\\left( 1 \\right)}+\\cdots +\\beta _kx^{\\left( k \\right)}\n",
    "$$\n",
    "在Logistics回归方法中，它的模型就是以下条件概率公式：\n",
    "$$\n",
    "P(y=1 \\mid x) =\\frac{1}{1+e^{-y}}=\\frac{1}{1+e^{-x^{'}\\beta}}\n",
    "$$\n",
    "在决策树方法中，它的模型就是一棵有着许多枝干的二叉树：\n",
    "\n",
    "<img src='./images/二叉树.jpg'>\n",
    "\n",
    "事实上，虽然对于某一个特定的机器学习方法来说，模型的形式是大致确定的，但是模型里面有非常多需要确定的参数，参数不同，模型也就不同，我们将**所有这些可能的模型组成的集合称为模型的假设空间(hypothesis space)**。\n",
    "\n",
    "对于决策函数模型来说，假设空间如下所示：\n",
    "$$\n",
    "\\mathcal{F}=\\left\\{f \\mid Y=f_\\theta(X), \\theta \\in \\mathbf{R}^n\\right\\}\n",
    "$$\n",
    "对于条件概率模型来说，假设空间如下所示：\n",
    "$$\n",
    "\\mathcal{F}=\\left\\{P \\mid P_\\theta(Y \\mid X), \\theta \\in \\mathbf{R}^n\\right\\}\n",
    "$$\n",
    "其中，$\\theta$则是模型中所有参数组成的向量，所有这些参数的集合也称为参数空间(parameter space)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型的形式有了，但是模型里面的各种参数信息我们是不知道的。那么接下来要做的就是通过使用给定的样本数据，在茫茫无际的模型假设空间中找到最优的那个模型，换言之，为这个模型在参数空间中找到一个参数组合$\\theta$使得模型最优。\n",
    "\n",
    "那么，我们应该如何找到这个最优的模型呢？这就是策略需要考虑的事了，而**所有机器学习方法的策略都是相似的——让风险函数最小化。**什么是风险函数呢？我们接着往下看。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**· 损失函数**\n",
    "\n",
    "我们先引入损失函数的概念。损失函数度量模型在一次预测中的“误差”，记为$L(Y, f(X))$，这里的误差指的是预测值$f(X)$与真实值$Y$的不一致程度。不同机器学习方法所采用的损失函数有所不同，常见的损失函数有以下几种：\n",
    "\n",
    "1. 0-1损失函数\n",
    "$$\n",
    "L(Y, f(X))= \\begin{cases}1, & Y \\neq f(X) \\\\ 0, & Y=f(X)\\end{cases}\n",
    "$$\n",
    "这种损失函数常用于解决分类问题的模型，分类错误则函数赋值为1，正确则赋值为0.\n",
    "\n",
    "2. 平方损失函数\n",
    "$$\n",
    "L(Y, f(X))=(Y-f(X))^2\n",
    "$$\n",
    "这种损失函数在回归问题中最常见，大家有没有意识到它就是线性回归方法的损失函数呢？\n",
    "\n",
    "3. 对数损失函数\n",
    "$$\n",
    "L(Y, P(Y \\mid X))=-\\log P(Y \\mid X)\n",
    "$$\n",
    "这种损失函数常用于以条件概率为模型的方法。\n",
    "\n",
    "以上三种损失函数是最基础的损失函数，实际的机器学习方法中会对这些损失函数进行一些改进与优化以增强模型的性能与稳定性。\n",
    "\n",
    "**· 风险函数——经验风险、结构风险、正则化**\n",
    "\n",
    "要衡量一个模型在一个数据集上的表现，只度量模型在单次预测上的误差肯定是不足够的，接下来我们引入风险函数的定义。风险函数则度量模型对所有训练集数据预测中的“平均好坏”，它又可以分为经验风险函数与结构风险函数。\n",
    "\n",
    "经验风险函数非常好理解，它就是模型$f(X)$（或$P(Y \\mid X)$）在训练数据集$T$上损失函数的平均值：\n",
    "$$\n",
    "R_{\\mathrm{emp}}(f)=\\frac{1}{N} \\sum_{i=1}^N L\\left(y_i, f\\left(x_i\\right)\\right)\n",
    "$$\n",
    "显然，经验风险函数衡量的就是模型在训练集上的平均误差。而找到模型假设空间中最优模型的策略就是风险函数最小化，我们便可以让经验风险函数最小化，将问题转化为一个最优化问题：\n",
    "$$\n",
    "\\min _{f \\in \\mathcal{F}} \\frac{1}{N} \\sum_{i=1}^N L\\left(y_i, f\\left(x_i\\right)\\right)\n",
    "$$\n",
    "经验风险最小化，就是模型在训练集的平均误差最小化，于是我们可以得知，以经验风险函数最小化为策略可以使模型**在训练集上的**误差最低，精度最高。\n",
    "\n",
    "看到这里，可能有同学会问：既然这个模型在训练集上误差最低，那这个策略是不是完美的呢？答案是：未必。因为绝大多数机器学习方法的最终目的是对未知新数据有好的预测效果，而不是对已知数据有好的预测效果。换句话说，我们评判模型的好坏应当着眼于其测试集上的性能而不是训练集上的性能。以经验风险函数最小化为策略确实可以使模型在训练集上的误差最低，但是这样的模型在测试集上的表现未必让人满意，因为可能会出现**过拟合现象**。\n",
    "\n",
    "我们在这里浅浅解释一下过拟合，进一步讨论会放在下面的部分。通俗地讲，过拟合就是模型对训练集上的数据特征过度地学习，把一些事实上不重要的噪声特征也纳入了模型，导致模型的复杂度过高，对未知数据的预测能力降低。简单地说，过拟合就是“钻了牛角尖，对一些细枝末节的东西过于在意”。\n",
    "\n",
    "那么，如何防止过拟合呢？我们在前面的解释中可以看到，过度学习的一大表现就是模型的复杂度过高，那如果我在原来的经验风险函数中加入一个对模型复杂度的“惩罚”，是不是就可以解决了这一问题呢？答案是肯定的，这就是**结构风险函数**的来由，它的公式为：\n",
    "$$\n",
    "R_{\\mathrm{srm}}(f)=\\frac{1}{N} \\sum_{i=1}^N L\\left(y_i, f\\left(x_i\\right)\\right)+\\lambda J(f)\n",
    "$$\n",
    "其中，$J(f)$是模型的复杂度，每个模型的复杂度函数定义都有不同。模型越复杂，$J(f)$越高；$\\lambda \\geqslant 0$是惩罚系数，$\\lambda$越高，复杂度的惩罚就越大。结构风险小的模型要求模型的训练集平均误差与模型复杂度都同时小，这使得它对于未知的测试集数据有较好的预测。让结构风险函数最小化也被称为**正则化**，如下所示：\n",
    "$$\n",
    "\\min _{f \\in \\mathcal{F}} \\frac{1}{N} \\sum_{i=1}^N L\\left(y_i, f\\left(x_i\\right)\\right)+\\lambda J(f)\n",
    "$$\n",
    "总结一下，机器学习方法的策略有两种：经验风险函数最小化与结构风险函数最小化。前者不限制模型的复杂度，对训练数据集的特征学习充分，但是可能产生过拟合；后者限制模型的复杂度，不容易使模型过拟合，但是过度的正则化会使模型对特征的学习不充分（这种情况被称为欠拟合）。正则化程度的选取，需要通过调参过程确定，这方面的内容将在后续课程提及。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经知晓了学习最优参数的策略实际上就是一个最优化问题，那么最后一个步骤就是针对这些最优化问题进行计算，这就是“算法”需要考虑的事了。\n",
    "\n",
    "算法是指学习模型的具体计算方法。这里面涉及数值计算的许多方法，是较为困难的部分，且每个机器学习方法都有各自独特的计算方法，因此在后续的机器学习方法讲解上，我们不会注重对“算法”部分的讲解。大家只需要稍作了解即可。\n",
    "\n",
    "注意：我们在这里说的算法特指计算方法，和在前面大章节说的“机器学习算法”中的算法并不一样，“机器学习算法”中的算法更多的理解为是一种“方法”，讲的人多了也便成了一种说法上的固定搭配。我们在后续的课程中也会经常使用“机器学习算法”、“xxx算法”这样的说法，这其中的算法实际上是方法，而非计算方法，望大家理解！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 模型评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过了3.2的机器学习三要素步骤后，我们现在成功训练出了一个机器学习模型$f(X)$。但是，任务还没有完全结束，我们还有一项重要的任务需要进行——模型已经训练好了，可是它的“好不好”需要如何进行评估呢？那么这就是本章节需要探讨的内容！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 评估指标——测试误差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们在前面提到过，机器学习更注重对未知数据的预测能力，因此未参与到模型训练过程的测试集数据的误差(test error)便可以用来评估模型对未知数据的预测能力。\n",
    "\n",
    "当损失函数$L$给定后，我们便可以计算测试集的平均误差了。假设训练完毕的模型为$Y=\\hat{f}(X)$，则关于测试集的平均损失为：\n",
    "$$\n",
    "e_{\\mathrm{test}}=\\frac{1}{N^{\\prime}} \\sum_{i=1}^{N^{\\prime}} L\\left(y_i, \\hat{f}\\left(x_i\\right)\\right)\n",
    "$$\n",
    "其中，$N^{\\prime}$为测试集样本容量。\n",
    "\n",
    "值得注意的是，测试误差所采用的损失函数$L$与策略中的训练误差损失函数$L$未必是一致的，这种情况在分类问题上比较常见。例如，Xgboost模型所采用的训练损失函数是对数损失函数的变式，而测试损失函数则根据需求变化——既可以是0-1损失函数，也可以是诸如精确率(precision)与召回率(recall)等指标。当然，也有两者一致的情况，如回归问题的训练、测试损失函数都为平方损失函数。\n",
    "\n",
    "最后，如果一个模型的测试误差小，说明它对未知数据有较强的预测能力，我们称这种对未知数据的预测能力为**泛化能力(generalization ability)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 过拟合及其解析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一章节，我们对过拟合现象进行简要的剖析，并借用一个M次多项式建模的例子向大家直观地展示过拟合的后果。\n",
    "\n",
    "我们先给出过拟合的定义：过拟合是指学习时选择的模型所包含的参数过多，以至于其对训练集数据有很好的预测效果，但是对测试集数据效果很差的现象。\n",
    "\n",
    "下面，我们用一个例子向大家说明过拟合的危害。假设给定一个样本数为10的一维训练数据集：\n",
    "$$\n",
    "T=\\left\\{\\left(x_1, y_1\\right),\\left(x_2, y_2\\right), \\cdots,\\left(x_{10}, y_{10}\\right)\\right\\}\n",
    "$$\n",
    "我们需要对这10个给定样本点进行多项式拟合任务——即假定给定数据是由某个$M$次多项式函数生成的，我们要找出最有可能产生这些数据的$M$次多项式函数。\n",
    "\n",
    "设$M$次多项式为：\n",
    "$$\n",
    "f_M(x, w)=w_0+w_1 x+w_2 x^2+\\cdots+w_M x^M=\\sum_{j=0}^M w_j x^j\n",
    "$$\n",
    "根据多项式函数的知识，由于我们有10个数据点，因此可以拟合0~9次多项式函数。样本点分布与各阶多项式曲线拟合的情况如下：\n",
    "\n",
    "<img src='./images/多项式.png'>\n",
    "\n",
    "四张图分别为$M=0,M=1,M=3,M=9$的拟合曲线情况，注意到每张图中都有一条相同的曲线，那是产生这些样本点的实际多项式模型（之所以不是完全贴合，是因为有噪声的添加）。\n",
    "\n",
    "可以看到，$M=0$时，多项式模型就是一条常数直线，拟合效果非常差，属于“欠拟合”；$M=1$时，多项式模型仅能学习到样本点的大致趋势，拟合效果也不佳。$M=3$时，模型已经能较好的拟合样本点了，且我们知道它已经很接近真实模型了；$M=9$时，模型对样本点做到了完全的贴合，但是我们知道训练样本点是存在噪声的，这种过度的拟合实际上把噪声信息也学习进了模型当中。这样的模型一旦对未知数据进行预测，效果将惨不忍睹！想象一下，还是由那一条曲线产生新的测试样本点，九阶模型预测的误差将有多大呢！\n",
    "\n",
    "从上述例子中，我们可以洞见训练误差、测试误差与模型复杂度间的大致关系。在模型复杂度较低的时候，训练、测试误差都很高，这是因为模型过于简单导致对数据特征的学习不充分，也就是模型欠拟合；随着模型复杂度的提高，训练、测试误差同步下降，但是测试误差存在一个理论的极小值点，在极小值点之后，随着复杂度的继续提高，测试误差将逐渐增大，发生过拟合。\n",
    "\n",
    "<img src='./images/误差.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 模型选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们在前面遵循机器学习方法三要素训练出了一个模型，并使用测试误差对这个模型进行了评估，那么最后一个环节来了——如何在众多可能的模型中选择出相对最优的那个模型呢？事实上，这个问题可以分为两部分：\n",
    "1. 如何在不同类别的模型中选出最好的类别；\n",
    "\n",
    "2. 如何在一类模型中选出最优的那组参数。\n",
    "\n",
    "对于第一个问题，我认为首先要做的是对各种模型都要有一定的了解，清楚每一种模型适合使用在怎样的场景下，这样在拿到数据后，我们心里自然就会知道可能有哪些模型适合处理这样的数据。如果可能存在多个模型效果相近，我们则可以比较这些模型的指标，选取最优者。\n",
    "\n",
    "关键问题是第二个。我们在前面的分析中一直有一个假设：模型是存在理论最优解的，然而在实际情况中我们不可能找到这种理想解，只能在众多参数组合中找到相对最优的那组。简单来说，就是需要我们列出可能的参数组合，再使用一定的选择方法找出最优的那组，并以这组参数作为当前最优的参数解。一个常用的选择方法就是交叉验证法，这个方法的介绍我们将留在后续章节，在这里我们先埋下一个坑，敬请期待！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d04da679f0afee458c3e357f6d2cf382c79de022618e35f1262af9ecf478f5e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
